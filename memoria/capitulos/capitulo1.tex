\chapter{Introducción}
\label{cap:capitulo1}
\setcounter{page}{1}

La robótica engloba ciencia, ingeniería y tecnología, y su objetivo es el de desarrollar máquinas que realicen tareas de forma automática. El término robot proviene de la palabra checa \textit{robota}, que significa \textit{trabajo forzado}, y se utilizó por primera vez en la obra de teatro RUR (Rossum's Universal Robots) del autor Karel Capek, estrenada en 1921.\\

Los robots se pueden clasificar en dos grandes campos: robots industriales y robots de servicio. Según la norma internacional ISO 8373:2012 un robot industrial es un manipulador multifuncional, reprogramable y controlado automáticamente, programable en tres o más ejes, y puede estar fijo en un área o móvil para su uso en aplicaciones de automatización industrial. Por otro lado, según la Federación Internacional de Robótica (IFR), un robot de servicio es un robot que opera de forma parcial o totalmente autónoma para realizar servicios útiles para el bienestar de los humanos, excluyendo operaciones de manufactura.\\

En este primer capítulo se pretende dar un contexto amplio al lector sobre el presente trabajo. Se comienza presentando de forma general la robótica de servicio, campo en el cual se enmarca este trabajo, y se continúa avanzando por los distintos conceptos en los que se basa la investigación y desarrollo llevado a cabo.

\section{Robótica de servicio}
\label{sec:robotica} % etiqueta para luego referenciar esta sección

En los últimos años, la robótica de servicio está obteniendo un auge exponencial. Cada vez son más los campos en los que los robots ayudan a los seres humanos ---por ejemplo--- intentando mejorar su calidad de vida, ayudándoles a realizar tareas peligrosas o proporcionando simplemente una compañía agradable a aquellos que lo necesitan. Entre las aplicaciones más importantes encontramos las siguientes:

\begin{itemize}
 \item \textit{Limpieza.} Aspiradoras domésticas como iRobot Roomba 980 o limpiadores de ventanas como WinBot 950 (Figura \ref{fig:robots_limpieza}). Robots caracterizados por realizar tareas de navegación con el objetivo de recorrer completamente una zona mientras llevan a cabo labores de limpieza.\\

\begin{figure}[h!]
  \begin{center}
    \subcapcentertrue
    \subfigure[iRobot Roomba 980]{\includegraphics[width=55mm]{figs/roomba.png}}
    \hspace{2mm}
    \subfigure[WinBot 950]{\includegraphics[width=73mm]{figs/winbot.jpg}}
  \end{center}
\caption{Ejemplos de robots de limpieza.}
\label{fig:robots_limpieza}
\end{figure}

\item \textit{Inspección.} Cartografías 3D, inspección de plantas petrolíferas, aerogeneradores o minas. Suelen ser lugares de difícil acceso para los humanos, por lo que resulta idóneo el uso de robots cuadrúpedos o drones. Los robots con cuatro patas son actualmente los autómatas terrestres más estables del mercado y tienen la capacidad de recorrer terrenos inestables o incluso subir y bajar escaleras. Uno de los más populares es Spot, de Boston Dynamics (Figura \ref{fig:spot}).\\

\begin{figure} [h!]
  \begin{center}
    \includegraphics[width=75mm]{figs/spot.jpg}
  \end{center}
  \caption{Robot Spot de Boston Dynamics.}
  \label{fig:spot}
\end{figure}

\item \textit{Educación.} Aquellos robots enfocados a la docencia, tanto infantil como universitaria. Podemos destacar modelos como mBot, con posibilidad de programación a través de bloques con mBlock IDE\footnote{mBlock IDE: \url{https://ide.mblock.cc}}, o modelos como el TurtleBot, con soporte ROS\footnote{ROS: \url{https://www.ros.org/}}. Ambos mostrados en la Figura \ref{fig:robots_educacion}.\\

\begin{figure}[h!]
  \begin{center}
    \subcapcentertrue
    \subfigure[mBot]{\includegraphics[width=67mm]{figs/mbot.jpg}}
    \subfigure[TurtleBot2 ]{\includegraphics[width=52mm]{figs/turtlebot2.jpg}}
  \end{center}
\caption{Ejemplos de robots para educación.}
\label{fig:robots_educacion}
\end{figure}

\item \textit{Conducción autónoma.} Una tecnología cada vez más madura y extendida. Empresas como Waymo (Figura \ref{fig:coches_autonomos}) o AutoX ya están comercializando productos reales que llevan a cabo esta tarea, proporcionando servicios de taxi autónomos. Otros fabricantes como Tesla comercializan también coches semi-autónomos.\\

\begin{figure}[h!]
  \begin{center}
    \subcapcentertrue
    \subfigure[Taxi de Waymo]{\includegraphics[width=75mm]{figs/waymo.jpg}}
    \hspace{2mm}
    \subfigure[Tesla Model 3]{\includegraphics[width=54mm]{figs/tesla.jpg}}
  \end{center}
\caption{Ejemplos de coches autónomos.}
\label{fig:coches_autonomos}
\end{figure}

\item \textit{Logística.} Robots destinados a agilizar el transporte de materiales o productos dentro de una fábrica o almacén. Existen dos grandes grupos: AGV (Vehículo Guiado Automático) y AMR (Robot Móvil Autónomo). Un ejemplo serían los robots Kiva, los cuales trabajan en las instalaciones de Amazon (Figura \ref{fig:kiva}).

\begin{figure} [h!]
  \begin{center}
    \includegraphics[width=90mm]{figs/amazon_kiva.png}
  \end{center}
  \caption{Robots Kiva de Amazon.}
  \label{fig:kiva}
\end{figure}

\item \textit{Ámbito sanitario.} Es uno de los campos más amplios dentro de la robótica de servicio, donde existen autómatas realizando múltiples tareas. Podemos encontrar exoesqueletos enfocados en la rehabilitación de la marcha humana como el Atlas de Marsi-Bionics, o robots ayudantes en cirugía como Da Vinci o Mako (Figura \ref{fig:robots_cirugia}).

\begin{figure}[h!]
  \begin{center}
    \subcapcentertrue
    \subfigure[Robot DaVinci]{\includegraphics[width=70mm]{figs/robot-da-vinci.jpeg}}
    \subfigure[Robot Mako]{\includegraphics[width=55mm]{figs/mako.png}}
  \end{center}
\caption{Ejemplos de robots ayudantes en cirugía.}
\label{fig:robots_cirugia}
\end{figure}

Además, en los últimos años está surgiendo un nuevo tipo de robótica sanitaria: los robots de compañía o asistentes personales. Estos consiguen ---por ejemplo--- empatizar con los pacientes y hacerles pasar un rato más ameno. Para ello es indispensable conseguir una buena Interacción Humano Robot o HRI (Human Robot Interaction), tema del cual trata la siguiente sección. Un ejemplo de robot de compañía lo encontramos con Robin (Figura \ref{fig:robin}), el cual ayuda a los niños a superar el miedo de ir al médico.

\begin{figure} [h!]
  \begin{center}
    \includegraphics[width=8cm]{figs/robin.png}
  \end{center}
  \caption{Robot Robin.}
  \label{fig:robin}
\end{figure}
\end{itemize}

\section{Interacción Humano Robot (HRI)}
\label{sec:interaccion_humano_robot}

Podemos definir el HRI como el campo de estudio que intenta comprender, diseñar y evaluar la interacción entre los robots y los seres humanos. Debido a que los robots están cada vez más presentes en nuestras vidas, esta rama de investigación nace con la necesidad de que estos tengan la capacidad de colaborar y vivir con nosotros, los humanos.\\

La definición de HRI se remonta al año 1941, donde Isaac Asimov habla por primera vez de ello en su novela \textit{Yo, Robot}. Además, este autor definió una serie de leyes que se conocen como \textit{Las Tres Leyes de la Robótica} y que promueven una interacción segura entre humanos y robots. Las tres leyes son las siguientes:

\begin{itemize}
    \item \textit{Primera Ley.} Un robot no hará daño a un ser humano ni, por inacción, permitirá que un ser humano sufra daño.
    \item \textit{Segunda Ley.} Un robot debe cumplir las órdenes dadas por los seres humanos, a excepción de aquellas que entren en conflicto con la primera ley.
    \item \textit{Tercera Ley.} Un robot debe proteger su propia existencia en la medida en que esta protección no entre en conflicto con la primera o la segunda ley.
\end{itemize}

Actualmente, estas leyes representan el código moral y, con los años, han sido modificadas por Isaac Asimov y otros autores para conseguir mayor perfección. Además, Asimov agregó una cuarta ley por encima de esas tres que viene a ser una generalización de la primera, \textit{La Ley Cero}: Un robot no puede dañar a la humanidad o, por inacción, permitir que la humanidad sufra daños.\\

En el artículo \cite{hri_distancing} se realiza un estudio enfocado en cómo el trato proporcionado por un robot a un humano influía en la distancia física de ambos. Para realizar los experimentos usaron un robot (Figura \ref{fig:hri_distancing}) que era capaz de expresar emociones a través de gestos y los resultados demostraron que si el robot ejercía un trato poco social y nada empático, la distancia con el humano aumentaba. En cambio, si el robot expresaba un comportamiento amigable y comprensivo, la distancia con el humano disminuía, ya que el nivel de confianza con el robot aumentaba. Por lo tanto, si lo que queremos es que los robots sean capaces de colaborar y vivir con nosotros, debemos ser capaces de que estos actúen con empatía, comprensión y amabilidad hacia los seres humanos.\\

\begin{figure} [h!]
  \begin{center}
    \includegraphics[width=13cm]{figs/hri_distancing.jpg}
  \end{center}
  \caption{Robot usado en el estudio del artículo \cite{hri_distancing}.}
  \label{fig:hri_distancing}
\end{figure}

\subsection{Problemática. Paradoja de Moravec}

Según Dautenhahn en el artículo \cite{hri_dautenhahn}, el robot debe adaptarse a nuestra forma de expresión y nos debe comprender tal como somos y actuamos. Esto es algo realmente complicado para una máquina, ya que no tienen la capacidad de razonar; un robot únicamente se limita a ejecutar órdenes que previamente han sido programadas, y las reglas de un entorno social humano pueden ser muy variadas y poco esperadas.\\

Según Moravec en su libro \cite{moravec}, los actos voluntarios de un humano requieren de poca computación para una máquina, mientras que los actos no conscientes e involuntarios requieren de grandes esfuerzos computacionales. Moravec afirmó: <<comparativamente es fácil conseguir que las computadoras muestren capacidades similares a las de un humano adulto en tests de inteligencia, y difícil o imposible lograr que posean las habilidades perceptivas y motrices de un bebé de un año>>. Esto, según él, es debido a la evolución biológica humana.\\

Todas nuestras habilidades han sido perfeccionadas a lo largo de millones de años por el proceso de selección natural (Figura \ref{fig:evolucion_humana}) y, por lo tanto, sería lógico pensar que si intentamos replicar dichas habilidades en una máquina, nos tomaría como mínimo el mismo tiempo proporcionalmente. Muchas de nuestras acciones más valiosas, como coger objetos, reconocer voces, prestar atención, las habilidades sociales, etc. son involuntarias, y es eso lo que provoca que aplicarles ingeniería inversa sea muy complicado. Sin embargo, habilidades como las matemáticas resultan complejas para nosotros, ya que nuestro cerebro no está preparado para ello, y muy triviales para las máquinas.\\

\begin{figure} [h!]
  \begin{center}
    \includegraphics[width=13cm]{figs/evolucion_humana.png}
  \end{center}
  \caption{Evolución del ser humano. Selección natural.}
  \label{fig:evolucion_humana}
\end{figure}

Conociendo toda esta problemática parece casi imposible que un robot sea capaz de interaccionar con un humano, pero existen numerosos avances en la ingeniería que aportan un poco de claridad y optimismo al HRI.

\subsection{Soluciones}

Una interacción completa de humano-humano está regida por la vista, el oído y el tacto. Esos tres sentidos proporcionan toda la información que posteriormente nuestro cerebro procesará y razonará. Podemos concluir diciendo entonces que la interacción entre un humano y un robot estará compuesta por dos fases: \textit{percepción} y \textit{razonamiento}. Además, después de haber razonado, habría que actuar adecuadamente para que la interacción prosiga, pero esto ya se escapa del contexto de este trabajo. 

\subsubsection{Percepción}
\label{sec:percepcion}

Lo que para nosotros serían los sentidos, en los robots lo podemos sustituir por sensores (Figura \ref{fig:ejemplos_sensores}): cámaras para la vista, micrófonos para el oído o sensores de presión para el tacto. Además de estos, existen múltiples variantes más y con mayor o menor precisión en su tarea. Podríamos decir que esta fase de la interacción está bastante bien cubierta y de algún modo es muy semejante a la humana.\\

\begin{figure}[h!]
  \begin{center}
    \subcapcentertrue
    \subfigure[Cámara]{\includegraphics[width=50mm]{figs/camara.jpg}}
    \subfigure[Micrófono]{\includegraphics[width=50mm]{figs/microfono.jpg}}
    \subfigure[Sensor de presión]{\includegraphics[width=50mm]{figs/sensor_presion.png}}
  \end{center}
\caption{Ejemplos de sensores.}
\label{fig:ejemplos_sensores}
\end{figure}

Pero los sensores por si solos no tienen ningún valor ya que, más allá de recoger información, deben existir algoritmos que saquen conclusiones de todos esos datos. Un ejemplo de procesamiento puede ser la detección de personas en los fotogramas capturados por una cámara o la extracción de palabras del audio capturado por un micrófono.

\subsubsection{Razonamiento} 
\label{sec:razonamiento}

Sin lugar a dudas es la habilidad más compleja y la que más investigación necesita. A día de hoy no se ha conseguido implementar en un robot razonamiento que se asemeje al de un humano, pero si que se utilizan diversos trucos que simulan ese \textit{razonamiento}:

\begin{itemize}
\item \textit{Contexto de una conversación.} La frase <<No he visto ninguno>> puede tener múltiples significados dependiendo del tema que se esté tratando en la conversación. Se podría estar expresando que no se ha visto ningún error en la carta que se está escribiendo o que no se ha visto llegar el taxi que se había pedido. Dicho de otro modo, un robot no puede entender debidamente una frase suelta, pues necesita un contexto. Existen modelos de lenguaje, como GPT-3 (Figura \ref{fig:gpt3}), que consiguen simular el entendimiento de un diálogo, pero en realidad sólo están repitiendo conversaciones con las que el autómata ha sido entrenado.

\begin{figure} [h!]
  \begin{center}
    \includegraphics[width=12cm]{figs/gpt3.jpg}
  \end{center}
  \caption{Ejemplo de conversación con GPT-3 en OpenAI.}
  \label{fig:gpt3}
\end{figure}

\item \textit{Atención.} Mediante reconocimiento facial el robot puede realizar un seguimiento con la mirada a la cara del sujeto con el que está interactuando. Esto por ejemplo, simularía que el robot está prestando atención a una conversación.

\item \textit{Compresión de la situación emocional.} A través de la detección de emociones o expresiones faciales del sujeto con el que se está interactuando, el robot puede actuar de una manera u otra simulando que está comprendiendo la situación emocional.

\end{itemize}

Temas como el reconocimiento facial o la detección de personas, son frentes de investigación dentro de la \textit{Visión Artificial}, que es una rama muy amplia y de vital importancia dentro de la robótica, y se describe a continuación.

\section{Visión Artificial}

Los seres humanos utilizamos nuestros ojos para, de alguna manera, comprender todo aquello que nos rodea. El objetivo de la visión artificial es trasladar esa misma habilidad a una máquina, esto es, que sea capaz de percibir información visual del entorno (a través de una o más cámaras) y actuar según la situación. Para ello, la imagen percibida pasa por las siguientes fases:

\begin{enumerate}
    \item \textit{Digitalización.} Proceso de transformación que sufre una imagen analógica a otra digital para que pueda ser manipulada por un ordenador. Una máquina solo maneja números, por lo que la imagen ha de estar representada como una matriz de números (píxeles).
    
    \item \textit{Preprocesamiento.} En la etapa anterior es muy probable que las imágenes sufran degradaciones, como pérdida de definición o aparición de ruido. Esta etapa intenta subsanarlas con técnicas como la reducción de ruido o el realce del contraste.
    
    \item \textit{Segmentación.} Extracción de información contenida en la imagen mediante la descomposición de la misma en regiones significativas. Por ejemplo, determinar en una imagen qué píxeles pertenecen a los objetos y cuáles al fondo.
    
    \item \textit{Representación.} Tras realizar la segmentación se poseen píxeles en bruto. Se deberá elegir si se desean representar esos datos como el contorno de una región o como los puntos de dicha región. En eso consiste esta etapa.
    
    \item \textit{Descripción.} Selección de características o descriptores de la representación elegida para permitir la posterior clasificación de los objetos. Por ejemplo la cantidad de huecos o el perímetro del contorno.
    
    \item \textit{Reconocimiento.} Clasificación de los objetos de la imagen usando las características o descriptores obtenidos en la etapa anterior. A cada objeto se le asigna una etiqueta según corresponda, como \textit{Persona} o \textit{Planta}.
    
    \item \textit{Interpretación.} Etapa final, en la que se da significado a los objetos reconocidos. Por ejemplo, localizar qué objetos son dinámicos o estáticos, o detectar la posición en la que se encuentra un cuerpo.
\end{enumerate}

Estas fases son las empleadas bajo el paradigma de lo que se conoce como \textit{Visión Artificial Clásica}, enfocada a la utilización de algoritmos específicos para procesar imágenes y reconocer en ellas características básicas. Un ejemplo de ello lo vemos en el algoritmo de detección de bordes Canny\footnote{Canny: \url{https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html}} (Figura \ref{fig:canny}).\\

\begin{figure} [h!]
  \begin{center}
    \includegraphics[width=11cm]{figs/canny.png}
  \end{center}
  \caption{Ejemplo de detección de bordes con Canny.}
  \label{fig:canny}
\end{figure}

Sin embargo, el auge en los últimos años del Machine Learning (ML), que veremos en la siguiente sección (Sección \ref{sec:machine_learning}), está expandiendo exponencialmente las capacidades de la Visión Artificial. El Machine Learning comprende técnicas muy potentes que permiten resultados mucho mejores que los ofrecidos por la visión clásica, y además mucho más fáciles de implementar.

\section{Machine Learning}
\label{sec:machine_learning}

El Machine Learning o Aprendizaje Automático es una disciplina del campo de la Inteligencia Artificial que permite a un ordenador realizar tareas de manera automática sin previamente haber sido programadas explícitamente. Según el tipo de aprendizaje que realicen los algoritmos, estos se pueden clasificar en tres grandes grupos, cada uno de los cuales tiene determinadas características y diferentes aplicaciones finales que estudiaremos en la siguientes secciones.

\subsection{Aprendizaje supervisado}
\label{sec:aprendizaje_supervisado}

Usado para resolver problemas conocidos. Se le proporciona al algoritmo un conjunto de datos de entrada y sus salidas correspondientes, entonces el algoritmo se dedica a \textit{aprender} la relación entre las salidas y las entradas y con eso generar unos patrones a partir de los cuales realizará predicciones.\\

Utilizando un ejemplo más familiar, si queremos que nuestro algoritmo aprenda a detectar gatos, lo que debemos hacer es proporcionarle imágenes de ejemplo con gatos debidamente etiquetados. Una vez que el algoritmo haya recibido toda esa información y la haya procesado adecuadamente, la próxima vez que vea datos similares sabrá clasificarlos como gatos.\\

\noindent Dentro del aprendizaje supervisado se diferencian dos grandes tipos:
\begin{itemize}
\item \textit{\textbf{Regresión.}} Tiene como objetivo predecir la salida mediante una función que proporciona valores continuos. Por ejemplo predecir el precio de una vivienda a partir de su tamaño en metros cuadrados usando regresión lineal (Figura \ref{fig:ejemplo_regresion}).

\begin{figure} [h!]
  \begin{center}
    \includegraphics[width=9cm]{figs/ejemplo_regresion.png}
  \end{center}
  \caption{Ejemplo de regresión lineal.\\
  Predicción del precio de la vivienda.}
  \label{fig:ejemplo_regresion}
\end{figure}

Además de la regresión lineal ---que es el ejemplo más simple--- existen otros tipos, como la regresión logística o la regresión polinomial.

\item \textit{\textbf{Clasificación.}} Las salidas toman valores discretos en función de los valores de entrada. Si la salida posee únicamente dos valores discretos, entonces estamos ante una clasificación binaria. Si la salida puede tomar más de dos valores discretos, la clasificación será multiclase.

Un ejemplo de clasificación multiclase, sería la detección de objetos proporcionada por YOLO\footnote{YOLO: \url{https://pjreddie.com/darknet/yolo/}} (Figura \ref{fig:yolo}).

\begin{figure} [h!]
  \begin{center}
    \includegraphics[width=8cm]{figs/yolo.png}
  \end{center}
  \caption{Demo de la detección de objetos proporcionada por YOLO.}
  \label{fig:yolo}
\end{figure}

Los algoritmos más utilizados para realizar clasificación son SVM (Support Vector Machine), KNN (K Nearest Neighbour), Árboles de decisión y Redes Neuronales (Convolucionales, Recurrentes, etc.).

\end{itemize}

\subsection{Aprendizaje no supervisado}

En este caso, únicamente se le proporciona al algoritmo un conjunto de datos de entrada, y el propio algoritmo será el encargado de detectar patrones dentro de ese conjunto. A diferencia del aprendizaje supervisado, aquí no existe ningún etiquetado de los datos, por lo tanto, la máquina únicamente separara los datos por patrones pero no tendrá el concepto de qué son gatos o perros.\\

Un ejemplo, sería agrupar casas en función de la distancia al centro y del tamaño del jardín (Figura \ref{fig:ejemplo_clustering}). Esto se conoce como \textit{clustering} o segmentación.\\

\begin{figure} [h!]
  \begin{center}
    \includegraphics[width=9cm]{figs/ejemplo_no_supervisado.png}
  \end{center}
  \caption{Ejemplo de clustering.\\
            Agrupación de datos de casas.}
  \label{fig:ejemplo_clustering}
\end{figure}

En este tipo de aprendizaje, se puede indicar al algoritmo en cuántas clases se desea que se clasifiquen los datos, o se puede no indicar esta información y dejarle total libertad. En este último caso los científicos de datos tiene la posibilidad de aprender más sobre estos y puede encontrar patrones interesantes u ocultos que antes no eran visibles.

\subsection{Aprendizaje por refuerzo}

En este tipo de aprendizaje, no se proporcionan datos de entrada ni de salida. El algoritmo aprende a desarrollar una tarea a partir de un esquema de recompensas y penalizaciones ante las decisiones que toma en cada una de las iteraciones. Ya no sólo se trata de clasificar unos datos en unas determinadas clases, sino que tendremos muchos factores a la vez a los que prestar atención y actuar según la situación. Por eso este tipo de aprendizaje es sobre todo usado en robótica o videojuegos, pues ambos son máquinas o personajes actuando en un entorno cambiante (Figura \ref{fig:pacman}). A diferencia de los otros tipos de aprendizaje, en los que se intenta reducir el error, aquí se intenta maximizar la recompensa.

\begin{figure} [h!]
  \begin{center}
    \includegraphics[width=9cm]{figs/pacman.png}
  \end{center}
  \caption{Modelo de Aprendizaje por Refuerzo jugando a Pacman.}
  \label{fig:pacman}
\end{figure}

Se podría concluir afirmando que es una forma de entrenamiento basada en la fuerza bruta. Si el objetivo es que un robot recorra una habitación esquivando obstáculos, se le deberá someter a choques, acelerones, frenazos... para hacerle aprender lo que está bien y lo que está mal. El algoritmo más usado es Q-Learning.\\

La mayoría de las técnicas comprendidas en cualquiera de los tres tipos de aprendizaje explicados anteriormente (supervisado, no supervisado y por refuerzo), requieren de grandes esfuerzos computacionales. Sobre todo si se aplican sobre imágenes o grandes conjuntos de datos. Es por ello que lo más común es usar tarjetas gráficas muy potentes para realizar este tipo de trabajo. Pero no siempre se posee del dinero o del espacio donde alojar grandes centrales de procesamiento. Es aquí donde entran en juego los sistemas empotrados (Sección \ref{sec:empotrados}) y el afán por conseguir que, tareas muy costosas como ---por ejemplo--- la detección de objetos en imágenes, se puedan simplificar y funcionen en uno de estos sistemas empotrados con bajo poder computacional.

\section{Sistemas empotrados}
\label{sec:empotrados}
Un sistema empotrado (también conocido como \textit{embebido}) es un sistema caracterizado por su tamaño reducido y precio cometido, teniendo por contra un poder computacional relativamente bajo. Es por ello que su uso está siempre dirigido a realizar tareas específicas como ---por ejemplo--- un taxímetro o un cajero automático. Dichos sistemas no demandan una alta carga computacional y utilizar un sistema empotrado les proporciona ventajas como ---por ejemplo--- el ahorro energético, ya que estos tienen un consumo muy reducido.\\

El procesamiento se lleva a cabo en un microcontrolador, esto es, un microprocesador que posee además memoria y circuitos de entrada y salida. 

\subsection{Sistemas empotrados populares}
Existen varias plataformas de sistemas empotrados, aunque los dos más usados actualmente son Arduino\footnote{Arduino: \url{https://www.arduino.cc/}} y Raspberry\footnote{Raspberry: \url{https://www.raspberrypi.org/}} (Figura \ref{fig:logos_empotrados}). Ambos fabricantes proporcionan microcontroladores aunque Raspberry es más conocida por sus SBC (Single Board Computer).

\begin{figure}[h!]
  \begin{center}
    \subcapcentertrue
    \subfigure[Logo de Arduino]{\includegraphics[width=47mm]{figs/arduino-logo.png}}
    \hspace{2cm}
    \subfigure[Logo de Raspberry]{\includegraphics[width=27mm]{figs/raspberry-log.png}}
  \end{center}
\caption{Sistemas empotrados más usados.}
\label{fig:logos_empotrados}
\end{figure}

\paragraph{Arduino.} Fabricante especializado en la venta de microcontroladores. Posee modelos como los Arduino UNO R3 o Arduino Nano R3 (Figura \ref{fig:arduino_ejemplos}). Son microcontroladores integrados en el mismo chip con todos los componentes necesarios para su correcto funcionamiento (resistencias, condensadores, pines para conectar elementos, etc). Además de esto mencionado, la ventaja que nos proporciona este tipo de placas Arduino es que, a través de su entorno de desarrollo (Arduino IDE\footnote{Arduino IDE: \url{https://www.arduino.cc/en/software}}), tenemos la oportunidad de cargar código en los microcontroladores sin realizar métodos de \textit{flasheado} y compilación tediosos que si requieren otro tipo de microcontroladores.

\begin{figure}[h!]
  \begin{center}
    \subcapcentertrue
    \subfigure[Arduino UNO R3]{\includegraphics[width=57mm]{figs/arduino.jpg}}
    \hspace{1cm}
    \subfigure[Arduino Nano R3]{\includegraphics[width=57mm]{figs/arduino-nano-r3.png}}
  \end{center}
\caption{Ejemplos de placas Arduino.}
\label{fig:arduino_ejemplos}
\end{figure}

\paragraph{Raspberry.} Tiene a la venta microcontroladores como la Raspberry Pi Pico, pero su producto principal son los SBC, siendo la Raspberry Pi 4 Model B su último modelo (explicada más en profundidad en la Sección \ref{sec:rpi}). Ambas se muestran en la Figura \ref{fig:raspberry_ejemplos}. El concepto es muy parecido al de Arduino pero con características más robustas, no sólo se trata de un microcontrolador simple, es un ordenador completo con su propio sistema operativo, Raspberry Pi OS, basado en Debian (explicado más en profundidad en la Sección \ref{sec:raspberry_pi_os}). \\

\begin{figure}[h!]
  \begin{center}
    \subcapcentertrue
    \subfigure[Raspberry Pi Pico]{\includegraphics[width=57mm]{figs/raspberry-pi-pico.jpg}}
    \hspace{1cm}
    \subfigure[Raspberry Pi 4 Model B]{\includegraphics[width=62mm]{figs/raspberry_en_mano.png}}
  \end{center}
\caption{Ejemplos de placas Raspberry.}
\label{fig:raspberry_ejemplos}
\end{figure}

En este capítulo se ha introducido la Robótica de Servicio, dentro de cuya rama encontramos la Interacción Persona Robot o HRI, en la cual la Visión Artificial juega un papel fundamental; concretamente en los últimos años, el Machine Learning. Y un frente particular de esta rama de investigación es hacerlo funcionar en un sistema empotrado.\\

En este proyecto se presenta una herramienta de bajo coste que, mediante Visión Artificial y Machine Learning, es capaz de detectar emociones faciales, con el objetivo de poder ayudar así a mejorar el proceso de Interacción Humano Robot. En el Capítulo \ref{cap:capitulo2} se describe el problema a desarrollar y la metodología y el plan de trabajo que se ha llevado a cabo. En el Capítulo \ref{cap:capitulo3}, se exponen las herramientas hardware y software utilizadas. En el Capítulo \ref{cap:capitulo4} se describe el sistema desarrollado, así como los estudios y experimentos realizados. Por último, en el Capítulo \ref{cap:capitulo5}, se hace una breve recapitulación y se vierten las conclusiones finales.





